{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Setup and Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/assignments/project_3\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run __init__.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cook_df = pd.read_pickle('data/cook_sample_df.pkl')\n",
    "uci_df = pd.read_pickle('data/uci_df.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Select KBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def skb(data, feature):\n",
    "    \n",
    "    X_train, \\\n",
    "    X_test, \\\n",
    "    y_train, \\\n",
    "    y_test = train_test_split(data.drop(feature, axis=1), data[feature], test_size=0.25)\n",
    "    \n",
    "    skb = SelectKBest(k=100)\n",
    "    skb.fit(X_train, y_train)\n",
    "    \n",
    "    skb_feats = np.where(skb.get_support())[0] # gives the indices of the features selected.\n",
    "    skb_pvalues = skb.pvalues_\n",
    "    \n",
    "    return skb_feats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### UCI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "uci_skb_feats = skb(uci_df, 'labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>5</th>\n",
       "      <th>22</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>36</th>\n",
       "      <th>40</th>\n",
       "      <th>42</th>\n",
       "      <th>48</th>\n",
       "      <th>50</th>\n",
       "      <th>52</th>\n",
       "      <th>...</th>\n",
       "      <th>466</th>\n",
       "      <th>471</th>\n",
       "      <th>472</th>\n",
       "      <th>473</th>\n",
       "      <th>475</th>\n",
       "      <th>477</th>\n",
       "      <th>490</th>\n",
       "      <th>493</th>\n",
       "      <th>494</th>\n",
       "      <th>496</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1071</th>\n",
       "      <td>474</td>\n",
       "      <td>470</td>\n",
       "      <td>487</td>\n",
       "      <td>538</td>\n",
       "      <td>483</td>\n",
       "      <td>476</td>\n",
       "      <td>473</td>\n",
       "      <td>431</td>\n",
       "      <td>487</td>\n",
       "      <td>485</td>\n",
       "      <td>...</td>\n",
       "      <td>485</td>\n",
       "      <td>475</td>\n",
       "      <td>520</td>\n",
       "      <td>477</td>\n",
       "      <td>584</td>\n",
       "      <td>492</td>\n",
       "      <td>453</td>\n",
       "      <td>350</td>\n",
       "      <td>451</td>\n",
       "      <td>475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1297</th>\n",
       "      <td>474</td>\n",
       "      <td>472</td>\n",
       "      <td>491</td>\n",
       "      <td>419</td>\n",
       "      <td>471</td>\n",
       "      <td>479</td>\n",
       "      <td>488</td>\n",
       "      <td>465</td>\n",
       "      <td>567</td>\n",
       "      <td>529</td>\n",
       "      <td>...</td>\n",
       "      <td>472</td>\n",
       "      <td>489</td>\n",
       "      <td>524</td>\n",
       "      <td>477</td>\n",
       "      <td>430</td>\n",
       "      <td>471</td>\n",
       "      <td>444</td>\n",
       "      <td>381</td>\n",
       "      <td>558</td>\n",
       "      <td>492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>484</td>\n",
       "      <td>456</td>\n",
       "      <td>472</td>\n",
       "      <td>536</td>\n",
       "      <td>472</td>\n",
       "      <td>475</td>\n",
       "      <td>434</td>\n",
       "      <td>442</td>\n",
       "      <td>526</td>\n",
       "      <td>500</td>\n",
       "      <td>...</td>\n",
       "      <td>487</td>\n",
       "      <td>480</td>\n",
       "      <td>513</td>\n",
       "      <td>476</td>\n",
       "      <td>385</td>\n",
       "      <td>471</td>\n",
       "      <td>479</td>\n",
       "      <td>602</td>\n",
       "      <td>516</td>\n",
       "      <td>477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>464</td>\n",
       "      <td>487</td>\n",
       "      <td>472</td>\n",
       "      <td>438</td>\n",
       "      <td>485</td>\n",
       "      <td>481</td>\n",
       "      <td>437</td>\n",
       "      <td>419</td>\n",
       "      <td>529</td>\n",
       "      <td>469</td>\n",
       "      <td>...</td>\n",
       "      <td>473</td>\n",
       "      <td>470</td>\n",
       "      <td>493</td>\n",
       "      <td>479</td>\n",
       "      <td>354</td>\n",
       "      <td>508</td>\n",
       "      <td>498</td>\n",
       "      <td>432</td>\n",
       "      <td>533</td>\n",
       "      <td>473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>471</td>\n",
       "      <td>486</td>\n",
       "      <td>495</td>\n",
       "      <td>512</td>\n",
       "      <td>495</td>\n",
       "      <td>476</td>\n",
       "      <td>470</td>\n",
       "      <td>445</td>\n",
       "      <td>532</td>\n",
       "      <td>509</td>\n",
       "      <td>...</td>\n",
       "      <td>472</td>\n",
       "      <td>478</td>\n",
       "      <td>466</td>\n",
       "      <td>479</td>\n",
       "      <td>598</td>\n",
       "      <td>486</td>\n",
       "      <td>477</td>\n",
       "      <td>587</td>\n",
       "      <td>515</td>\n",
       "      <td>478</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      5    22   30   31   36   40   42   48   50   52  ...   466  471  472  \\\n",
       "1071  474  470  487  538  483  476  473  431  487  485 ...   485  475  520   \n",
       "1297  474  472  491  419  471  479  488  465  567  529 ...   472  489  524   \n",
       "386   484  456  472  536  472  475  434  442  526  500 ...   487  480  513   \n",
       "307   464  487  472  438  485  481  437  419  529  469 ...   473  470  493   \n",
       "750   471  486  495  512  495  476  470  445  532  509 ...   472  478  466   \n",
       "\n",
       "      473  475  477  490  493  494  496  \n",
       "1071  477  584  492  453  350  451  475  \n",
       "1297  477  430  471  444  381  558  492  \n",
       "386   476  385  471  479  602  516  477  \n",
       "307   479  354  508  498  432  533  473  \n",
       "750   479  598  486  477  587  515  478  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uci_df_skb = uci_df[uci_skb_feats]\n",
    "uci_df_skb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(440, 100)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uci_df_skb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([  5,  22,  30,  31,  36,  40,  42,  48,  50,  52,  55,  56,  62,  64,\n",
       "        72,  80,  81,  90,  92,  98, 101, 105, 110, 117, 124, 125, 128, 130,\n",
       "       137, 140, 141, 148, 157, 158, 159, 160, 165, 190, 200, 208, 212, 214,\n",
       "       217, 224, 225, 241, 243, 246, 254, 259, 262, 283, 285, 287, 322, 323,\n",
       "       325, 326, 329, 330, 331, 336, 338, 340, 341, 344, 348, 357, 365, 372,\n",
       "       377, 378, 379, 384, 398, 412, 414, 416, 418, 419, 420, 422, 423, 424,\n",
       "       435, 442, 453, 460, 461, 462, 466, 471, 472, 473, 475, 477, 490, 493,\n",
       "       494, 496],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uci_df_skb.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "uci_df_skb = pd.concat([uci_df_skb, uci_df['labels']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>5</th>\n",
       "      <th>22</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>36</th>\n",
       "      <th>40</th>\n",
       "      <th>42</th>\n",
       "      <th>48</th>\n",
       "      <th>50</th>\n",
       "      <th>52</th>\n",
       "      <th>...</th>\n",
       "      <th>471</th>\n",
       "      <th>472</th>\n",
       "      <th>473</th>\n",
       "      <th>475</th>\n",
       "      <th>477</th>\n",
       "      <th>490</th>\n",
       "      <th>493</th>\n",
       "      <th>494</th>\n",
       "      <th>496</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1071</th>\n",
       "      <td>474</td>\n",
       "      <td>470</td>\n",
       "      <td>487</td>\n",
       "      <td>538</td>\n",
       "      <td>483</td>\n",
       "      <td>476</td>\n",
       "      <td>473</td>\n",
       "      <td>431</td>\n",
       "      <td>487</td>\n",
       "      <td>485</td>\n",
       "      <td>...</td>\n",
       "      <td>475</td>\n",
       "      <td>520</td>\n",
       "      <td>477</td>\n",
       "      <td>584</td>\n",
       "      <td>492</td>\n",
       "      <td>453</td>\n",
       "      <td>350</td>\n",
       "      <td>451</td>\n",
       "      <td>475</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1297</th>\n",
       "      <td>474</td>\n",
       "      <td>472</td>\n",
       "      <td>491</td>\n",
       "      <td>419</td>\n",
       "      <td>471</td>\n",
       "      <td>479</td>\n",
       "      <td>488</td>\n",
       "      <td>465</td>\n",
       "      <td>567</td>\n",
       "      <td>529</td>\n",
       "      <td>...</td>\n",
       "      <td>489</td>\n",
       "      <td>524</td>\n",
       "      <td>477</td>\n",
       "      <td>430</td>\n",
       "      <td>471</td>\n",
       "      <td>444</td>\n",
       "      <td>381</td>\n",
       "      <td>558</td>\n",
       "      <td>492</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>484</td>\n",
       "      <td>456</td>\n",
       "      <td>472</td>\n",
       "      <td>536</td>\n",
       "      <td>472</td>\n",
       "      <td>475</td>\n",
       "      <td>434</td>\n",
       "      <td>442</td>\n",
       "      <td>526</td>\n",
       "      <td>500</td>\n",
       "      <td>...</td>\n",
       "      <td>480</td>\n",
       "      <td>513</td>\n",
       "      <td>476</td>\n",
       "      <td>385</td>\n",
       "      <td>471</td>\n",
       "      <td>479</td>\n",
       "      <td>602</td>\n",
       "      <td>516</td>\n",
       "      <td>477</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>464</td>\n",
       "      <td>487</td>\n",
       "      <td>472</td>\n",
       "      <td>438</td>\n",
       "      <td>485</td>\n",
       "      <td>481</td>\n",
       "      <td>437</td>\n",
       "      <td>419</td>\n",
       "      <td>529</td>\n",
       "      <td>469</td>\n",
       "      <td>...</td>\n",
       "      <td>470</td>\n",
       "      <td>493</td>\n",
       "      <td>479</td>\n",
       "      <td>354</td>\n",
       "      <td>508</td>\n",
       "      <td>498</td>\n",
       "      <td>432</td>\n",
       "      <td>533</td>\n",
       "      <td>473</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>471</td>\n",
       "      <td>486</td>\n",
       "      <td>495</td>\n",
       "      <td>512</td>\n",
       "      <td>495</td>\n",
       "      <td>476</td>\n",
       "      <td>470</td>\n",
       "      <td>445</td>\n",
       "      <td>532</td>\n",
       "      <td>509</td>\n",
       "      <td>...</td>\n",
       "      <td>478</td>\n",
       "      <td>466</td>\n",
       "      <td>479</td>\n",
       "      <td>598</td>\n",
       "      <td>486</td>\n",
       "      <td>477</td>\n",
       "      <td>587</td>\n",
       "      <td>515</td>\n",
       "      <td>478</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        5   22   30   31   36   40   42   48   50   52   ...    471  472  473  \\\n",
       "1071  474  470  487  538  483  476  473  431  487  485   ...    475  520  477   \n",
       "1297  474  472  491  419  471  479  488  465  567  529   ...    489  524  477   \n",
       "386   484  456  472  536  472  475  434  442  526  500   ...    480  513  476   \n",
       "307   464  487  472  438  485  481  437  419  529  469   ...    470  493  479   \n",
       "750   471  486  495  512  495  476  470  445  532  509   ...    478  466  479   \n",
       "\n",
       "      475  477  490  493  494  496  labels  \n",
       "1071  584  492  453  350  451  475      -1  \n",
       "1297  430  471  444  381  558  492       1  \n",
       "386   385  471  479  602  516  477      -1  \n",
       "307   354  508  498  432  533  473      -1  \n",
       "750   598  486  477  587  515  478       1  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uci_df_skb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(440, 101)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uci_df_skb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "uci_df_skb.to_pickle('./data/uci_df_skb.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  8,   9,  11,  29,  46,  75,  78,  82,  83,  94,  96, 116, 135,\n",
       "       138, 154, 178, 183, 184, 198, 201, 223, 237, 244, 255, 258, 270,\n",
       "       285, 296, 299, 301, 304, 313, 316, 331, 334, 335, 337, 339, 342,\n",
       "       367, 368, 373, 451, 457, 458, 489, 492, 498, 505, 508, 513, 528,\n",
       "       548, 560, 597, 615, 618, 620, 623, 632, 675, 678, 681, 682, 692,\n",
       "       702, 711, 716, 717, 737, 742, 755, 760, 765, 766, 770, 778, 803,\n",
       "       808, 809, 823, 824, 827, 830, 832, 837, 848, 860, 865, 866, 876,\n",
       "       902, 921, 935, 937, 943, 953, 954, 957, 998])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skb(cook_df, 'target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat_000</th>\n",
       "      <th>feat_008</th>\n",
       "      <th>feat_010</th>\n",
       "      <th>feat_040</th>\n",
       "      <th>feat_045</th>\n",
       "      <th>feat_060</th>\n",
       "      <th>feat_074</th>\n",
       "      <th>feat_084</th>\n",
       "      <th>feat_093</th>\n",
       "      <th>feat_115</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_920</th>\n",
       "      <th>feat_930</th>\n",
       "      <th>feat_932</th>\n",
       "      <th>feat_934</th>\n",
       "      <th>feat_936</th>\n",
       "      <th>feat_952</th>\n",
       "      <th>feat_970</th>\n",
       "      <th>feat_976</th>\n",
       "      <th>feat_986</th>\n",
       "      <th>feat_997</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-3.034374</td>\n",
       "      <td>0.712301</td>\n",
       "      <td>-0.352660</td>\n",
       "      <td>-0.933290</td>\n",
       "      <td>-0.357363</td>\n",
       "      <td>-0.346608</td>\n",
       "      <td>0.199698</td>\n",
       "      <td>0.088485</td>\n",
       "      <td>-0.228922</td>\n",
       "      <td>1.568832</td>\n",
       "      <td>...</td>\n",
       "      <td>0.926191</td>\n",
       "      <td>0.269275</td>\n",
       "      <td>0.162382</td>\n",
       "      <td>1.608609</td>\n",
       "      <td>0.878471</td>\n",
       "      <td>-1.045563</td>\n",
       "      <td>1.160833</td>\n",
       "      <td>0.458572</td>\n",
       "      <td>-0.133944</td>\n",
       "      <td>0.403179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.818852</td>\n",
       "      <td>1.318110</td>\n",
       "      <td>0.563542</td>\n",
       "      <td>0.188723</td>\n",
       "      <td>-0.115562</td>\n",
       "      <td>1.425692</td>\n",
       "      <td>-0.616379</td>\n",
       "      <td>0.135313</td>\n",
       "      <td>0.569699</td>\n",
       "      <td>0.721256</td>\n",
       "      <td>...</td>\n",
       "      <td>0.609046</td>\n",
       "      <td>-0.276530</td>\n",
       "      <td>-1.202342</td>\n",
       "      <td>0.683418</td>\n",
       "      <td>0.328876</td>\n",
       "      <td>-0.038551</td>\n",
       "      <td>1.385970</td>\n",
       "      <td>-0.207488</td>\n",
       "      <td>0.628380</td>\n",
       "      <td>1.688175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.508119</td>\n",
       "      <td>-0.060162</td>\n",
       "      <td>0.468768</td>\n",
       "      <td>-0.487132</td>\n",
       "      <td>-0.389987</td>\n",
       "      <td>-0.419138</td>\n",
       "      <td>1.086299</td>\n",
       "      <td>-0.910851</td>\n",
       "      <td>-0.480257</td>\n",
       "      <td>0.073463</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.987504</td>\n",
       "      <td>0.246811</td>\n",
       "      <td>0.646459</td>\n",
       "      <td>-0.400285</td>\n",
       "      <td>-0.612021</td>\n",
       "      <td>-0.974378</td>\n",
       "      <td>1.996198</td>\n",
       "      <td>-0.358419</td>\n",
       "      <td>0.078776</td>\n",
       "      <td>-0.415439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.110053</td>\n",
       "      <td>-1.176142</td>\n",
       "      <td>-0.142638</td>\n",
       "      <td>1.631945</td>\n",
       "      <td>-0.288534</td>\n",
       "      <td>-0.446730</td>\n",
       "      <td>-0.479363</td>\n",
       "      <td>0.481733</td>\n",
       "      <td>-0.121196</td>\n",
       "      <td>0.411768</td>\n",
       "      <td>...</td>\n",
       "      <td>1.203833</td>\n",
       "      <td>-0.616253</td>\n",
       "      <td>1.851868</td>\n",
       "      <td>0.682661</td>\n",
       "      <td>0.895353</td>\n",
       "      <td>-1.302499</td>\n",
       "      <td>-0.450258</td>\n",
       "      <td>0.273583</td>\n",
       "      <td>-0.222644</td>\n",
       "      <td>0.871494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.355486</td>\n",
       "      <td>0.209040</td>\n",
       "      <td>-1.494295</td>\n",
       "      <td>1.021404</td>\n",
       "      <td>1.170621</td>\n",
       "      <td>-1.709896</td>\n",
       "      <td>0.026212</td>\n",
       "      <td>-1.212099</td>\n",
       "      <td>0.091621</td>\n",
       "      <td>1.400238</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.535322</td>\n",
       "      <td>0.887778</td>\n",
       "      <td>-0.007076</td>\n",
       "      <td>0.611038</td>\n",
       "      <td>-0.037532</td>\n",
       "      <td>0.211362</td>\n",
       "      <td>0.971910</td>\n",
       "      <td>2.121686</td>\n",
       "      <td>-0.433505</td>\n",
       "      <td>0.667061</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feat_000  feat_008  feat_010  feat_040  feat_045  feat_060  feat_074  \\\n",
       "0 -3.034374  0.712301 -0.352660 -0.933290 -0.357363 -0.346608  0.199698   \n",
       "1  0.818852  1.318110  0.563542  0.188723 -0.115562  1.425692 -0.616379   \n",
       "2 -0.508119 -0.060162  0.468768 -0.487132 -0.389987 -0.419138  1.086299   \n",
       "3 -0.110053 -1.176142 -0.142638  1.631945 -0.288534 -0.446730 -0.479363   \n",
       "4 -1.355486  0.209040 -1.494295  1.021404  1.170621 -1.709896  0.026212   \n",
       "\n",
       "   feat_084  feat_093  feat_115    ...     feat_920  feat_930  feat_932  \\\n",
       "0  0.088485 -0.228922  1.568832    ...     0.926191  0.269275  0.162382   \n",
       "1  0.135313  0.569699  0.721256    ...     0.609046 -0.276530 -1.202342   \n",
       "2 -0.910851 -0.480257  0.073463    ...    -0.987504  0.246811  0.646459   \n",
       "3  0.481733 -0.121196  0.411768    ...     1.203833 -0.616253  1.851868   \n",
       "4 -1.212099  0.091621  1.400238    ...    -0.535322  0.887778 -0.007076   \n",
       "\n",
       "   feat_934  feat_936  feat_952  feat_970  feat_976  feat_986  feat_997  \n",
       "0  1.608609  0.878471 -1.045563  1.160833  0.458572 -0.133944  0.403179  \n",
       "1  0.683418  0.328876 -0.038551  1.385970 -0.207488  0.628380  1.688175  \n",
       "2 -0.400285 -0.612021 -0.974378  1.996198 -0.358419  0.078776 -0.415439  \n",
       "3  0.682661  0.895353 -1.302499 -0.450258  0.273583 -0.222644  0.871494  \n",
       "4  0.611038 -0.037532  0.211362  0.971910  2.121686 -0.433505  0.667061  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cook_skb_feats = skb(cook_df, 'target')\n",
    "\n",
    "cook_df_skb = cook_df[cook_skb_feats]\n",
    "cook_df_skb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cook_df_skb = pd.concat([cook_df_skb, cook_df['target']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat_000</th>\n",
       "      <th>feat_008</th>\n",
       "      <th>feat_010</th>\n",
       "      <th>feat_040</th>\n",
       "      <th>feat_045</th>\n",
       "      <th>feat_060</th>\n",
       "      <th>feat_074</th>\n",
       "      <th>feat_084</th>\n",
       "      <th>feat_093</th>\n",
       "      <th>feat_115</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_930</th>\n",
       "      <th>feat_932</th>\n",
       "      <th>feat_934</th>\n",
       "      <th>feat_936</th>\n",
       "      <th>feat_952</th>\n",
       "      <th>feat_970</th>\n",
       "      <th>feat_976</th>\n",
       "      <th>feat_986</th>\n",
       "      <th>feat_997</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-3.034374</td>\n",
       "      <td>0.712301</td>\n",
       "      <td>-0.352660</td>\n",
       "      <td>-0.933290</td>\n",
       "      <td>-0.357363</td>\n",
       "      <td>-0.346608</td>\n",
       "      <td>0.199698</td>\n",
       "      <td>0.088485</td>\n",
       "      <td>-0.228922</td>\n",
       "      <td>1.568832</td>\n",
       "      <td>...</td>\n",
       "      <td>0.269275</td>\n",
       "      <td>0.162382</td>\n",
       "      <td>1.608609</td>\n",
       "      <td>0.878471</td>\n",
       "      <td>-1.045563</td>\n",
       "      <td>1.160833</td>\n",
       "      <td>0.458572</td>\n",
       "      <td>-0.133944</td>\n",
       "      <td>0.403179</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.818852</td>\n",
       "      <td>1.318110</td>\n",
       "      <td>0.563542</td>\n",
       "      <td>0.188723</td>\n",
       "      <td>-0.115562</td>\n",
       "      <td>1.425692</td>\n",
       "      <td>-0.616379</td>\n",
       "      <td>0.135313</td>\n",
       "      <td>0.569699</td>\n",
       "      <td>0.721256</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.276530</td>\n",
       "      <td>-1.202342</td>\n",
       "      <td>0.683418</td>\n",
       "      <td>0.328876</td>\n",
       "      <td>-0.038551</td>\n",
       "      <td>1.385970</td>\n",
       "      <td>-0.207488</td>\n",
       "      <td>0.628380</td>\n",
       "      <td>1.688175</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.508119</td>\n",
       "      <td>-0.060162</td>\n",
       "      <td>0.468768</td>\n",
       "      <td>-0.487132</td>\n",
       "      <td>-0.389987</td>\n",
       "      <td>-0.419138</td>\n",
       "      <td>1.086299</td>\n",
       "      <td>-0.910851</td>\n",
       "      <td>-0.480257</td>\n",
       "      <td>0.073463</td>\n",
       "      <td>...</td>\n",
       "      <td>0.246811</td>\n",
       "      <td>0.646459</td>\n",
       "      <td>-0.400285</td>\n",
       "      <td>-0.612021</td>\n",
       "      <td>-0.974378</td>\n",
       "      <td>1.996198</td>\n",
       "      <td>-0.358419</td>\n",
       "      <td>0.078776</td>\n",
       "      <td>-0.415439</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.110053</td>\n",
       "      <td>-1.176142</td>\n",
       "      <td>-0.142638</td>\n",
       "      <td>1.631945</td>\n",
       "      <td>-0.288534</td>\n",
       "      <td>-0.446730</td>\n",
       "      <td>-0.479363</td>\n",
       "      <td>0.481733</td>\n",
       "      <td>-0.121196</td>\n",
       "      <td>0.411768</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.616253</td>\n",
       "      <td>1.851868</td>\n",
       "      <td>0.682661</td>\n",
       "      <td>0.895353</td>\n",
       "      <td>-1.302499</td>\n",
       "      <td>-0.450258</td>\n",
       "      <td>0.273583</td>\n",
       "      <td>-0.222644</td>\n",
       "      <td>0.871494</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.355486</td>\n",
       "      <td>0.209040</td>\n",
       "      <td>-1.494295</td>\n",
       "      <td>1.021404</td>\n",
       "      <td>1.170621</td>\n",
       "      <td>-1.709896</td>\n",
       "      <td>0.026212</td>\n",
       "      <td>-1.212099</td>\n",
       "      <td>0.091621</td>\n",
       "      <td>1.400238</td>\n",
       "      <td>...</td>\n",
       "      <td>0.887778</td>\n",
       "      <td>-0.007076</td>\n",
       "      <td>0.611038</td>\n",
       "      <td>-0.037532</td>\n",
       "      <td>0.211362</td>\n",
       "      <td>0.971910</td>\n",
       "      <td>2.121686</td>\n",
       "      <td>-0.433505</td>\n",
       "      <td>0.667061</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feat_000  feat_008  feat_010  feat_040  feat_045  feat_060  feat_074  \\\n",
       "0 -3.034374  0.712301 -0.352660 -0.933290 -0.357363 -0.346608  0.199698   \n",
       "1  0.818852  1.318110  0.563542  0.188723 -0.115562  1.425692 -0.616379   \n",
       "2 -0.508119 -0.060162  0.468768 -0.487132 -0.389987 -0.419138  1.086299   \n",
       "3 -0.110053 -1.176142 -0.142638  1.631945 -0.288534 -0.446730 -0.479363   \n",
       "4 -1.355486  0.209040 -1.494295  1.021404  1.170621 -1.709896  0.026212   \n",
       "\n",
       "   feat_084  feat_093  feat_115   ...    feat_930  feat_932  feat_934  \\\n",
       "0  0.088485 -0.228922  1.568832   ...    0.269275  0.162382  1.608609   \n",
       "1  0.135313  0.569699  0.721256   ...   -0.276530 -1.202342  0.683418   \n",
       "2 -0.910851 -0.480257  0.073463   ...    0.246811  0.646459 -0.400285   \n",
       "3  0.481733 -0.121196  0.411768   ...   -0.616253  1.851868  0.682661   \n",
       "4 -1.212099  0.091621  1.400238   ...    0.887778 -0.007076  0.611038   \n",
       "\n",
       "   feat_936  feat_952  feat_970  feat_976  feat_986  feat_997  target  \n",
       "0  0.878471 -1.045563  1.160833  0.458572 -0.133944  0.403179       1  \n",
       "1  0.328876 -0.038551  1.385970 -0.207488  0.628380  1.688175       0  \n",
       "2 -0.612021 -0.974378  1.996198 -0.358419  0.078776 -0.415439       1  \n",
       "3  0.895353 -1.302499 -0.450258  0.273583 -0.222644  0.871494       0  \n",
       "4 -0.037532  0.211362  0.971910  2.121686 -0.433505  0.667061       0  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cook_df_skb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cook_df_skb.to_pickle('./data/cook_df_skb.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Decision Tree Regressor and KNN (Iterative Method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) UCI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>491</th>\n",
       "      <th>492</th>\n",
       "      <th>493</th>\n",
       "      <th>494</th>\n",
       "      <th>495</th>\n",
       "      <th>496</th>\n",
       "      <th>497</th>\n",
       "      <th>498</th>\n",
       "      <th>499</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1071</th>\n",
       "      <td>483</td>\n",
       "      <td>453</td>\n",
       "      <td>531</td>\n",
       "      <td>462</td>\n",
       "      <td>445</td>\n",
       "      <td>474</td>\n",
       "      <td>487</td>\n",
       "      <td>480</td>\n",
       "      <td>504</td>\n",
       "      <td>475</td>\n",
       "      <td>...</td>\n",
       "      <td>481</td>\n",
       "      <td>483</td>\n",
       "      <td>350</td>\n",
       "      <td>451</td>\n",
       "      <td>555</td>\n",
       "      <td>475</td>\n",
       "      <td>483</td>\n",
       "      <td>505</td>\n",
       "      <td>506</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1297</th>\n",
       "      <td>490</td>\n",
       "      <td>470</td>\n",
       "      <td>448</td>\n",
       "      <td>489</td>\n",
       "      <td>499</td>\n",
       "      <td>474</td>\n",
       "      <td>494</td>\n",
       "      <td>478</td>\n",
       "      <td>515</td>\n",
       "      <td>478</td>\n",
       "      <td>...</td>\n",
       "      <td>477</td>\n",
       "      <td>510</td>\n",
       "      <td>381</td>\n",
       "      <td>558</td>\n",
       "      <td>469</td>\n",
       "      <td>492</td>\n",
       "      <td>496</td>\n",
       "      <td>525</td>\n",
       "      <td>461</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>489</td>\n",
       "      <td>487</td>\n",
       "      <td>534</td>\n",
       "      <td>482</td>\n",
       "      <td>537</td>\n",
       "      <td>484</td>\n",
       "      <td>439</td>\n",
       "      <td>476</td>\n",
       "      <td>450</td>\n",
       "      <td>487</td>\n",
       "      <td>...</td>\n",
       "      <td>484</td>\n",
       "      <td>494</td>\n",
       "      <td>602</td>\n",
       "      <td>516</td>\n",
       "      <td>507</td>\n",
       "      <td>477</td>\n",
       "      <td>468</td>\n",
       "      <td>530</td>\n",
       "      <td>448</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>478</td>\n",
       "      <td>486</td>\n",
       "      <td>632</td>\n",
       "      <td>464</td>\n",
       "      <td>510</td>\n",
       "      <td>464</td>\n",
       "      <td>536</td>\n",
       "      <td>477</td>\n",
       "      <td>468</td>\n",
       "      <td>479</td>\n",
       "      <td>...</td>\n",
       "      <td>474</td>\n",
       "      <td>506</td>\n",
       "      <td>432</td>\n",
       "      <td>533</td>\n",
       "      <td>521</td>\n",
       "      <td>473</td>\n",
       "      <td>498</td>\n",
       "      <td>526</td>\n",
       "      <td>477</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>478</td>\n",
       "      <td>493</td>\n",
       "      <td>545</td>\n",
       "      <td>493</td>\n",
       "      <td>500</td>\n",
       "      <td>471</td>\n",
       "      <td>480</td>\n",
       "      <td>476</td>\n",
       "      <td>483</td>\n",
       "      <td>486</td>\n",
       "      <td>...</td>\n",
       "      <td>481</td>\n",
       "      <td>491</td>\n",
       "      <td>587</td>\n",
       "      <td>515</td>\n",
       "      <td>539</td>\n",
       "      <td>478</td>\n",
       "      <td>481</td>\n",
       "      <td>521</td>\n",
       "      <td>521</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 501 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0    1    2    3    4    5    6    7    8    9   ...    491  492  493  \\\n",
       "1071  483  453  531  462  445  474  487  480  504  475   ...    481  483  350   \n",
       "1297  490  470  448  489  499  474  494  478  515  478   ...    477  510  381   \n",
       "386   489  487  534  482  537  484  439  476  450  487   ...    484  494  602   \n",
       "307   478  486  632  464  510  464  536  477  468  479   ...    474  506  432   \n",
       "750   478  493  545  493  500  471  480  476  483  486   ...    481  491  587   \n",
       "\n",
       "      494  495  496  497  498  499  labels  \n",
       "1071  451  555  475  483  505  506      -1  \n",
       "1297  558  469  492  496  525  461       1  \n",
       "386   516  507  477  468  530  448      -1  \n",
       "307   533  521  473  498  526  477      -1  \n",
       "750   515  539  478  481  521  521       1  \n",
       "\n",
       "[5 rows x 501 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uci_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target = uci_df['labels']\n",
    "uci_no_target = uci_df.drop(['labels'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(440, 500)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uci_no_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_r2_for_feature_knn(data, feature):\n",
    "    new_data = data.drop(feature, axis=1)\n",
    "    \n",
    "    X_tr, \\\n",
    "    X_ts,  \\\n",
    "    y_tr, \\\n",
    "    y_ts = train_test_split(\n",
    "        new_data,data[feature],test_size=0.25\n",
    "    )\n",
    "    \n",
    "    regressor = KNeighborsRegressor()\n",
    "    regressor.fit(X_tr, y_tr)\n",
    "    \n",
    "    score = regressor.score(X_ts, y_ts)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mean_r2_for_feature_knn(data, feature):\n",
    "    scores = []\n",
    "    for _ in range(50):\n",
    "        scores.append(calculate_r2_for_feature_knn(data, feature))\n",
    "        \n",
    "    scores = np.array(scores)\n",
    "    return scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on feature 1 of 500\n",
      "working on feature 2 of 500\n",
      "working on feature 3 of 500\n",
      "working on feature 4 of 500\n",
      "working on feature 5 of 500\n",
      "working on feature 6 of 500\n",
      "working on feature 7 of 500\n",
      "working on feature 8 of 500\n",
      "working on feature 9 of 500\n",
      "working on feature 10 of 500\n",
      "working on feature 11 of 500\n",
      "working on feature 12 of 500\n",
      "working on feature 13 of 500\n",
      "working on feature 14 of 500\n",
      "working on feature 15 of 500\n",
      "working on feature 16 of 500\n",
      "working on feature 17 of 500\n",
      "working on feature 18 of 500\n",
      "working on feature 19 of 500\n",
      "working on feature 20 of 500\n",
      "working on feature 21 of 500\n",
      "working on feature 22 of 500\n",
      "working on feature 23 of 500\n",
      "working on feature 24 of 500\n",
      "working on feature 25 of 500\n",
      "working on feature 26 of 500\n",
      "working on feature 27 of 500\n",
      "working on feature 28 of 500\n",
      "working on feature 29 of 500\n",
      "working on feature 30 of 500\n",
      "working on feature 31 of 500\n",
      "working on feature 32 of 500\n",
      "working on feature 33 of 500\n",
      "working on feature 34 of 500\n",
      "working on feature 35 of 500\n",
      "working on feature 36 of 500\n",
      "working on feature 37 of 500\n",
      "working on feature 38 of 500\n",
      "working on feature 39 of 500\n",
      "working on feature 40 of 500\n",
      "working on feature 41 of 500\n",
      "working on feature 42 of 500\n",
      "working on feature 43 of 500\n",
      "working on feature 44 of 500\n",
      "working on feature 45 of 500\n",
      "working on feature 46 of 500\n",
      "working on feature 47 of 500\n",
      "working on feature 48 of 500\n",
      "working on feature 49 of 500\n",
      "working on feature 50 of 500\n",
      "working on feature 51 of 500\n",
      "working on feature 52 of 500\n",
      "working on feature 53 of 500\n",
      "working on feature 54 of 500\n",
      "working on feature 55 of 500\n",
      "working on feature 56 of 500\n",
      "working on feature 57 of 500\n",
      "working on feature 58 of 500\n",
      "working on feature 59 of 500\n",
      "working on feature 60 of 500\n",
      "working on feature 61 of 500\n",
      "working on feature 62 of 500\n",
      "working on feature 63 of 500\n",
      "working on feature 64 of 500\n",
      "working on feature 65 of 500\n",
      "working on feature 66 of 500\n",
      "working on feature 67 of 500\n",
      "working on feature 68 of 500\n",
      "working on feature 69 of 500\n",
      "working on feature 70 of 500\n",
      "working on feature 71 of 500\n",
      "working on feature 72 of 500\n",
      "working on feature 73 of 500\n",
      "working on feature 74 of 500\n",
      "working on feature 75 of 500\n",
      "working on feature 76 of 500\n",
      "working on feature 77 of 500\n",
      "working on feature 78 of 500\n",
      "working on feature 79 of 500\n",
      "working on feature 80 of 500\n",
      "working on feature 81 of 500\n",
      "working on feature 82 of 500\n",
      "working on feature 83 of 500\n",
      "working on feature 84 of 500\n",
      "working on feature 85 of 500\n",
      "working on feature 86 of 500\n",
      "working on feature 87 of 500\n",
      "working on feature 88 of 500\n",
      "working on feature 89 of 500\n",
      "working on feature 90 of 500\n",
      "working on feature 91 of 500\n",
      "working on feature 92 of 500\n",
      "working on feature 93 of 500\n",
      "working on feature 94 of 500\n",
      "working on feature 95 of 500\n",
      "working on feature 96 of 500\n",
      "working on feature 97 of 500\n",
      "working on feature 98 of 500\n",
      "working on feature 99 of 500\n",
      "working on feature 100 of 500\n",
      "working on feature 101 of 500\n",
      "working on feature 102 of 500\n",
      "working on feature 103 of 500\n",
      "working on feature 104 of 500\n",
      "working on feature 105 of 500\n",
      "working on feature 106 of 500\n",
      "working on feature 107 of 500\n",
      "working on feature 108 of 500\n",
      "working on feature 109 of 500\n",
      "working on feature 110 of 500\n",
      "working on feature 111 of 500\n",
      "working on feature 112 of 500\n",
      "working on feature 113 of 500\n",
      "working on feature 114 of 500\n",
      "working on feature 115 of 500\n",
      "working on feature 116 of 500\n",
      "working on feature 117 of 500\n",
      "working on feature 118 of 500\n",
      "working on feature 119 of 500\n",
      "working on feature 120 of 500\n",
      "working on feature 121 of 500\n",
      "working on feature 122 of 500\n",
      "working on feature 123 of 500\n",
      "working on feature 124 of 500\n",
      "working on feature 125 of 500\n",
      "working on feature 126 of 500\n",
      "working on feature 127 of 500\n",
      "working on feature 128 of 500\n",
      "working on feature 129 of 500\n",
      "working on feature 130 of 500\n",
      "working on feature 131 of 500\n",
      "working on feature 132 of 500\n",
      "working on feature 133 of 500\n",
      "working on feature 134 of 500\n",
      "working on feature 135 of 500\n",
      "working on feature 136 of 500\n",
      "working on feature 137 of 500\n",
      "working on feature 138 of 500\n",
      "working on feature 139 of 500\n",
      "working on feature 140 of 500\n",
      "working on feature 141 of 500\n",
      "working on feature 142 of 500\n",
      "working on feature 143 of 500\n",
      "working on feature 144 of 500\n",
      "working on feature 145 of 500\n",
      "working on feature 146 of 500\n",
      "working on feature 147 of 500\n",
      "working on feature 148 of 500\n",
      "working on feature 149 of 500\n",
      "working on feature 150 of 500\n",
      "working on feature 151 of 500\n",
      "working on feature 152 of 500\n",
      "working on feature 153 of 500\n",
      "working on feature 154 of 500\n",
      "working on feature 155 of 500\n",
      "working on feature 156 of 500\n",
      "working on feature 157 of 500\n",
      "working on feature 158 of 500\n",
      "working on feature 159 of 500\n",
      "working on feature 160 of 500\n",
      "working on feature 161 of 500\n",
      "working on feature 162 of 500\n",
      "working on feature 163 of 500\n",
      "working on feature 164 of 500\n",
      "working on feature 165 of 500\n",
      "working on feature 166 of 500\n",
      "working on feature 167 of 500\n",
      "working on feature 168 of 500\n",
      "working on feature 169 of 500\n",
      "working on feature 170 of 500\n",
      "working on feature 171 of 500\n",
      "working on feature 172 of 500\n",
      "working on feature 173 of 500\n",
      "working on feature 174 of 500\n",
      "working on feature 175 of 500\n",
      "working on feature 176 of 500\n",
      "working on feature 177 of 500\n",
      "working on feature 178 of 500\n",
      "working on feature 179 of 500\n",
      "working on feature 180 of 500\n",
      "working on feature 181 of 500\n",
      "working on feature 182 of 500\n",
      "working on feature 183 of 500\n",
      "working on feature 184 of 500\n",
      "working on feature 185 of 500\n",
      "working on feature 186 of 500\n",
      "working on feature 187 of 500\n",
      "working on feature 188 of 500\n",
      "working on feature 189 of 500\n",
      "working on feature 190 of 500\n",
      "working on feature 191 of 500\n",
      "working on feature 192 of 500\n",
      "working on feature 193 of 500\n",
      "working on feature 194 of 500\n",
      "working on feature 195 of 500\n",
      "working on feature 196 of 500\n",
      "working on feature 197 of 500\n",
      "working on feature 198 of 500\n",
      "working on feature 199 of 500\n",
      "working on feature 200 of 500\n",
      "working on feature 201 of 500\n",
      "working on feature 202 of 500\n",
      "working on feature 203 of 500\n",
      "working on feature 204 of 500\n",
      "working on feature 205 of 500\n",
      "working on feature 206 of 500\n",
      "working on feature 207 of 500\n",
      "working on feature 208 of 500\n",
      "working on feature 209 of 500\n",
      "working on feature 210 of 500\n",
      "working on feature 211 of 500\n",
      "working on feature 212 of 500\n",
      "working on feature 213 of 500\n",
      "working on feature 214 of 500\n",
      "working on feature 215 of 500\n",
      "working on feature 216 of 500\n",
      "working on feature 217 of 500\n",
      "working on feature 218 of 500\n",
      "working on feature 219 of 500\n",
      "working on feature 220 of 500\n",
      "working on feature 221 of 500\n",
      "working on feature 222 of 500\n",
      "working on feature 223 of 500\n",
      "working on feature 224 of 500\n",
      "working on feature 225 of 500\n",
      "working on feature 226 of 500\n",
      "working on feature 227 of 500\n",
      "working on feature 228 of 500\n",
      "working on feature 229 of 500\n",
      "working on feature 230 of 500\n",
      "working on feature 231 of 500\n",
      "working on feature 232 of 500\n",
      "working on feature 233 of 500\n",
      "working on feature 234 of 500\n",
      "working on feature 235 of 500\n",
      "working on feature 236 of 500\n",
      "working on feature 237 of 500\n",
      "working on feature 238 of 500\n",
      "working on feature 239 of 500\n",
      "working on feature 240 of 500\n",
      "working on feature 241 of 500\n",
      "working on feature 242 of 500\n",
      "working on feature 243 of 500\n",
      "working on feature 244 of 500\n",
      "working on feature 245 of 500\n",
      "working on feature 246 of 500\n",
      "working on feature 247 of 500\n",
      "working on feature 248 of 500\n",
      "working on feature 249 of 500\n",
      "working on feature 250 of 500\n",
      "working on feature 251 of 500\n",
      "working on feature 252 of 500\n",
      "working on feature 253 of 500\n",
      "working on feature 254 of 500\n",
      "working on feature 255 of 500\n",
      "working on feature 256 of 500\n",
      "working on feature 257 of 500\n",
      "working on feature 258 of 500\n",
      "working on feature 259 of 500\n",
      "working on feature 260 of 500\n",
      "working on feature 261 of 500\n",
      "working on feature 262 of 500\n",
      "working on feature 263 of 500\n",
      "working on feature 264 of 500\n",
      "working on feature 265 of 500\n",
      "working on feature 266 of 500\n",
      "working on feature 267 of 500\n",
      "working on feature 268 of 500\n",
      "working on feature 269 of 500\n",
      "working on feature 270 of 500\n",
      "working on feature 271 of 500\n",
      "working on feature 272 of 500\n",
      "working on feature 273 of 500\n",
      "working on feature 274 of 500\n",
      "working on feature 275 of 500\n",
      "working on feature 276 of 500\n",
      "working on feature 277 of 500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on feature 278 of 500\n",
      "working on feature 279 of 500\n",
      "working on feature 280 of 500\n",
      "working on feature 281 of 500\n",
      "working on feature 282 of 500\n",
      "working on feature 283 of 500\n",
      "working on feature 284 of 500\n",
      "working on feature 285 of 500\n",
      "working on feature 286 of 500\n",
      "working on feature 287 of 500\n",
      "working on feature 288 of 500\n",
      "working on feature 289 of 500\n",
      "working on feature 290 of 500\n",
      "working on feature 291 of 500\n",
      "working on feature 292 of 500\n",
      "working on feature 293 of 500\n",
      "working on feature 294 of 500\n",
      "working on feature 295 of 500\n",
      "working on feature 296 of 500\n",
      "working on feature 297 of 500\n",
      "working on feature 298 of 500\n",
      "working on feature 299 of 500\n",
      "working on feature 300 of 500\n",
      "working on feature 301 of 500\n",
      "working on feature 302 of 500\n",
      "working on feature 303 of 500\n",
      "working on feature 304 of 500\n",
      "working on feature 305 of 500\n",
      "working on feature 306 of 500\n",
      "working on feature 307 of 500\n",
      "working on feature 308 of 500\n",
      "working on feature 309 of 500\n",
      "working on feature 310 of 500\n",
      "working on feature 311 of 500\n",
      "working on feature 312 of 500\n",
      "working on feature 313 of 500\n",
      "working on feature 314 of 500\n",
      "working on feature 315 of 500\n",
      "working on feature 316 of 500\n",
      "working on feature 317 of 500\n",
      "working on feature 318 of 500\n",
      "working on feature 319 of 500\n",
      "working on feature 320 of 500\n",
      "working on feature 321 of 500\n",
      "working on feature 322 of 500\n",
      "working on feature 323 of 500\n",
      "working on feature 324 of 500\n",
      "working on feature 325 of 500\n",
      "working on feature 326 of 500\n",
      "working on feature 327 of 500\n",
      "working on feature 328 of 500\n",
      "working on feature 329 of 500\n",
      "working on feature 330 of 500\n",
      "working on feature 331 of 500\n",
      "working on feature 332 of 500\n",
      "working on feature 333 of 500\n",
      "working on feature 334 of 500\n",
      "working on feature 335 of 500\n",
      "working on feature 336 of 500\n",
      "working on feature 337 of 500\n",
      "working on feature 338 of 500\n",
      "working on feature 339 of 500\n",
      "working on feature 340 of 500\n",
      "working on feature 341 of 500\n",
      "working on feature 342 of 500\n",
      "working on feature 343 of 500\n",
      "working on feature 344 of 500\n",
      "working on feature 345 of 500\n",
      "working on feature 346 of 500\n",
      "working on feature 347 of 500\n",
      "working on feature 348 of 500\n",
      "working on feature 349 of 500\n",
      "working on feature 350 of 500\n",
      "working on feature 351 of 500\n",
      "working on feature 352 of 500\n",
      "working on feature 353 of 500\n",
      "working on feature 354 of 500\n",
      "working on feature 355 of 500\n",
      "working on feature 356 of 500\n",
      "working on feature 357 of 500\n",
      "working on feature 358 of 500\n",
      "working on feature 359 of 500\n",
      "working on feature 360 of 500\n",
      "working on feature 361 of 500\n",
      "working on feature 362 of 500\n",
      "working on feature 363 of 500\n",
      "working on feature 364 of 500\n",
      "working on feature 365 of 500\n",
      "working on feature 366 of 500\n",
      "working on feature 367 of 500\n",
      "working on feature 368 of 500\n",
      "working on feature 369 of 500\n",
      "working on feature 370 of 500\n",
      "working on feature 371 of 500\n",
      "working on feature 372 of 500\n",
      "working on feature 373 of 500\n",
      "working on feature 374 of 500\n",
      "working on feature 375 of 500\n",
      "working on feature 376 of 500\n",
      "working on feature 377 of 500\n",
      "working on feature 378 of 500\n",
      "working on feature 379 of 500\n",
      "working on feature 380 of 500\n",
      "working on feature 381 of 500\n",
      "working on feature 382 of 500\n",
      "working on feature 383 of 500\n",
      "working on feature 384 of 500\n",
      "working on feature 385 of 500\n",
      "working on feature 386 of 500\n",
      "working on feature 387 of 500\n",
      "working on feature 388 of 500\n",
      "working on feature 389 of 500\n",
      "working on feature 390 of 500\n",
      "working on feature 391 of 500\n",
      "working on feature 392 of 500\n",
      "working on feature 393 of 500\n",
      "working on feature 394 of 500\n",
      "working on feature 395 of 500\n",
      "working on feature 396 of 500\n",
      "working on feature 397 of 500\n",
      "working on feature 398 of 500\n",
      "working on feature 399 of 500\n",
      "working on feature 400 of 500\n",
      "working on feature 401 of 500\n",
      "working on feature 402 of 500\n",
      "working on feature 403 of 500\n",
      "working on feature 404 of 500\n",
      "working on feature 405 of 500\n",
      "working on feature 406 of 500\n",
      "working on feature 407 of 500\n",
      "working on feature 408 of 500\n",
      "working on feature 409 of 500\n",
      "working on feature 410 of 500\n",
      "working on feature 411 of 500\n",
      "working on feature 412 of 500\n",
      "working on feature 413 of 500\n",
      "working on feature 414 of 500\n",
      "working on feature 415 of 500\n",
      "working on feature 416 of 500\n",
      "working on feature 417 of 500\n",
      "working on feature 418 of 500\n",
      "working on feature 419 of 500\n",
      "working on feature 420 of 500\n",
      "working on feature 421 of 500\n",
      "working on feature 422 of 500\n",
      "working on feature 423 of 500\n",
      "working on feature 424 of 500\n",
      "working on feature 425 of 500\n",
      "working on feature 426 of 500\n",
      "working on feature 427 of 500\n",
      "working on feature 428 of 500\n",
      "working on feature 429 of 500\n",
      "working on feature 430 of 500\n",
      "working on feature 431 of 500\n",
      "working on feature 432 of 500\n",
      "working on feature 433 of 500\n",
      "working on feature 434 of 500\n",
      "working on feature 435 of 500\n",
      "working on feature 436 of 500\n",
      "working on feature 437 of 500\n",
      "working on feature 438 of 500\n",
      "working on feature 439 of 500\n",
      "working on feature 440 of 500\n",
      "working on feature 441 of 500\n",
      "working on feature 442 of 500\n",
      "working on feature 443 of 500\n",
      "working on feature 444 of 500\n",
      "working on feature 445 of 500\n",
      "working on feature 446 of 500\n",
      "working on feature 447 of 500\n",
      "working on feature 448 of 500\n",
      "working on feature 449 of 500\n",
      "working on feature 450 of 500\n",
      "working on feature 451 of 500\n",
      "working on feature 452 of 500\n",
      "working on feature 453 of 500\n",
      "working on feature 454 of 500\n",
      "working on feature 455 of 500\n",
      "working on feature 456 of 500\n",
      "working on feature 457 of 500\n",
      "working on feature 458 of 500\n",
      "working on feature 459 of 500\n",
      "working on feature 460 of 500\n",
      "working on feature 461 of 500\n",
      "working on feature 462 of 500\n",
      "working on feature 463 of 500\n",
      "working on feature 464 of 500\n",
      "working on feature 465 of 500\n",
      "working on feature 466 of 500\n",
      "working on feature 467 of 500\n",
      "working on feature 468 of 500\n",
      "working on feature 469 of 500\n",
      "working on feature 470 of 500\n",
      "working on feature 471 of 500\n",
      "working on feature 472 of 500\n",
      "working on feature 473 of 500\n",
      "working on feature 474 of 500\n",
      "working on feature 475 of 500\n",
      "working on feature 476 of 500\n",
      "working on feature 477 of 500\n",
      "working on feature 478 of 500\n",
      "working on feature 479 of 500\n",
      "working on feature 480 of 500\n",
      "working on feature 481 of 500\n",
      "working on feature 482 of 500\n",
      "working on feature 483 of 500\n",
      "working on feature 484 of 500\n",
      "working on feature 485 of 500\n",
      "working on feature 486 of 500\n",
      "working on feature 487 of 500\n",
      "working on feature 488 of 500\n",
      "working on feature 489 of 500\n",
      "working on feature 490 of 500\n",
      "working on feature 491 of 500\n",
      "working on feature 492 of 500\n",
      "working on feature 493 of 500\n",
      "working on feature 494 of 500\n",
      "working on feature 495 of 500\n",
      "working on feature 496 of 500\n",
      "working on feature 497 of 500\n",
      "working on feature 498 of 500\n",
      "working on feature 499 of 500\n",
      "working on feature 500 of 500\n"
     ]
    }
   ],
   "source": [
    "KNN_results = []\n",
    "counter = 1\n",
    "for feature in uci_no_target.columns:\n",
    "    print('working on feature {} of 500'.format(counter))\n",
    "    mean_scores = mean_r2_for_feature_knn(uci_no_target, feature)\n",
    "    KNN_results.append(mean_scores)\n",
    "    counter +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "KNN_columns = [x for x, score in enumerate(KNN_results) if score > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[28,\n",
       " 48,\n",
       " 64,\n",
       " 105,\n",
       " 128,\n",
       " 153,\n",
       " 241,\n",
       " 281,\n",
       " 318,\n",
       " 336,\n",
       " 338,\n",
       " 378,\n",
       " 433,\n",
       " 442,\n",
       " 451,\n",
       " 453,\n",
       " 455,\n",
       " 472,\n",
       " 475,\n",
       " 493]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNN_columns\n",
    "\n",
    "any(i in KNN_columns for i in DTR_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_r2_for_feature_dtr(data, feature):\n",
    "    new_data = data.drop(feature, axis=1)\n",
    "    \n",
    "    X_tr, \\\n",
    "    X_ts,  \\\n",
    "    y_tr, \\\n",
    "    y_ts = train_test_split(\n",
    "        new_data,data[feature],test_size=0.25\n",
    "    )\n",
    "    \n",
    "    regressor = DecisionTreeRegressor()\n",
    "    regressor.fit(X_tr, y_tr)\n",
    "    \n",
    "    score = regressor.score(X_ts, y_ts)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mean_r2_for_feature_dtr(data, feature):\n",
    "    scores = []\n",
    "    for _ in range(50):\n",
    "        scores.append(calculate_r2_for_feature_dtr(data, feature))\n",
    "        \n",
    "    scores = np.array(scores)\n",
    "    return scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on feature 1 of 500\n",
      "working on feature 2 of 500\n",
      "working on feature 3 of 500\n",
      "working on feature 4 of 500\n",
      "working on feature 5 of 500\n",
      "working on feature 6 of 500\n",
      "working on feature 7 of 500\n",
      "working on feature 8 of 500\n",
      "working on feature 9 of 500\n",
      "working on feature 10 of 500\n",
      "working on feature 11 of 500\n",
      "working on feature 12 of 500\n",
      "working on feature 13 of 500\n",
      "working on feature 14 of 500\n",
      "working on feature 15 of 500\n",
      "working on feature 16 of 500\n",
      "working on feature 17 of 500\n",
      "working on feature 18 of 500\n",
      "working on feature 19 of 500\n",
      "working on feature 20 of 500\n",
      "working on feature 21 of 500\n",
      "working on feature 22 of 500\n",
      "working on feature 23 of 500\n",
      "working on feature 24 of 500\n",
      "working on feature 25 of 500\n",
      "working on feature 26 of 500\n",
      "working on feature 27 of 500\n",
      "working on feature 28 of 500\n",
      "working on feature 29 of 500\n",
      "working on feature 30 of 500\n",
      "working on feature 31 of 500\n",
      "working on feature 32 of 500\n",
      "working on feature 33 of 500\n",
      "working on feature 34 of 500\n",
      "working on feature 35 of 500\n",
      "working on feature 36 of 500\n",
      "working on feature 37 of 500\n",
      "working on feature 38 of 500\n",
      "working on feature 39 of 500\n",
      "working on feature 40 of 500\n",
      "working on feature 41 of 500\n",
      "working on feature 42 of 500\n",
      "working on feature 43 of 500\n",
      "working on feature 44 of 500\n",
      "working on feature 45 of 500\n",
      "working on feature 46 of 500\n",
      "working on feature 47 of 500\n",
      "working on feature 48 of 500\n",
      "working on feature 49 of 500\n",
      "working on feature 50 of 500\n",
      "working on feature 51 of 500\n",
      "working on feature 52 of 500\n",
      "working on feature 53 of 500\n",
      "working on feature 54 of 500\n",
      "working on feature 55 of 500\n",
      "working on feature 56 of 500\n",
      "working on feature 57 of 500\n",
      "working on feature 58 of 500\n",
      "working on feature 59 of 500\n",
      "working on feature 60 of 500\n",
      "working on feature 61 of 500\n",
      "working on feature 62 of 500\n",
      "working on feature 63 of 500\n",
      "working on feature 64 of 500\n",
      "working on feature 65 of 500\n",
      "working on feature 66 of 500\n",
      "working on feature 67 of 500\n",
      "working on feature 68 of 500\n",
      "working on feature 69 of 500\n",
      "working on feature 70 of 500\n",
      "working on feature 71 of 500\n",
      "working on feature 72 of 500\n",
      "working on feature 73 of 500\n",
      "working on feature 74 of 500\n",
      "working on feature 75 of 500\n",
      "working on feature 76 of 500\n",
      "working on feature 77 of 500\n",
      "working on feature 78 of 500\n",
      "working on feature 79 of 500\n",
      "working on feature 80 of 500\n",
      "working on feature 81 of 500\n",
      "working on feature 82 of 500\n",
      "working on feature 83 of 500\n",
      "working on feature 84 of 500\n",
      "working on feature 85 of 500\n",
      "working on feature 86 of 500\n",
      "working on feature 87 of 500\n",
      "working on feature 88 of 500\n",
      "working on feature 89 of 500\n",
      "working on feature 90 of 500\n",
      "working on feature 91 of 500\n",
      "working on feature 92 of 500\n",
      "working on feature 93 of 500\n",
      "working on feature 94 of 500\n",
      "working on feature 95 of 500\n",
      "working on feature 96 of 500\n",
      "working on feature 101 of 500\n",
      "working on feature 102 of 500\n",
      "working on feature 103 of 500\n",
      "working on feature 104 of 500\n",
      "working on feature 105 of 500\n",
      "working on feature 106 of 500\n",
      "working on feature 107 of 500\n",
      "working on feature 108 of 500\n",
      "working on feature 109 of 500\n",
      "working on feature 110 of 500\n",
      "working on feature 111 of 500\n",
      "working on feature 112 of 500\n",
      "working on feature 113 of 500\n",
      "working on feature 114 of 500\n",
      "working on feature 115 of 500\n",
      "working on feature 116 of 500\n",
      "working on feature 117 of 500\n",
      "working on feature 118 of 500\n",
      "working on feature 119 of 500\n",
      "working on feature 120 of 500\n",
      "working on feature 121 of 500\n",
      "working on feature 122 of 500\n",
      "working on feature 123 of 500\n",
      "working on feature 124 of 500\n",
      "working on feature 125 of 500\n",
      "working on feature 126 of 500\n",
      "working on feature 127 of 500\n",
      "working on feature 128 of 500\n",
      "working on feature 129 of 500\n",
      "working on feature 130 of 500\n",
      "working on feature 131 of 500\n",
      "working on feature 132 of 500\n",
      "working on feature 133 of 500\n",
      "working on feature 134 of 500\n",
      "working on feature 135 of 500\n",
      "working on feature 136 of 500\n",
      "working on feature 137 of 500\n",
      "working on feature 138 of 500\n",
      "working on feature 139 of 500\n",
      "working on feature 140 of 500\n",
      "working on feature 141 of 500\n",
      "working on feature 142 of 500\n",
      "working on feature 143 of 500\n",
      "working on feature 144 of 500\n",
      "working on feature 145 of 500\n",
      "working on feature 146 of 500\n",
      "working on feature 147 of 500\n",
      "working on feature 148 of 500\n",
      "working on feature 149 of 500\n",
      "working on feature 150 of 500\n",
      "working on feature 151 of 500\n",
      "working on feature 152 of 500\n",
      "working on feature 153 of 500\n",
      "working on feature 154 of 500\n",
      "working on feature 155 of 500\n",
      "working on feature 156 of 500\n",
      "working on feature 157 of 500\n",
      "working on feature 158 of 500\n",
      "working on feature 159 of 500\n",
      "working on feature 160 of 500\n",
      "working on feature 161 of 500\n",
      "working on feature 162 of 500\n",
      "working on feature 163 of 500\n",
      "working on feature 164 of 500\n",
      "working on feature 165 of 500\n",
      "working on feature 166 of 500\n",
      "working on feature 167 of 500\n",
      "working on feature 168 of 500\n",
      "working on feature 169 of 500\n",
      "working on feature 170 of 500\n",
      "working on feature 171 of 500\n",
      "working on feature 172 of 500\n",
      "working on feature 173 of 500\n",
      "working on feature 174 of 500\n",
      "working on feature 175 of 500\n",
      "working on feature 176 of 500\n",
      "working on feature 177 of 500\n",
      "working on feature 178 of 500\n",
      "working on feature 179 of 500\n",
      "working on feature 180 of 500\n",
      "working on feature 181 of 500\n",
      "working on feature 182 of 500\n",
      "working on feature 183 of 500\n",
      "working on feature 184 of 500\n",
      "working on feature 185 of 500\n",
      "working on feature 186 of 500\n",
      "working on feature 187 of 500\n",
      "working on feature 188 of 500\n",
      "working on feature 189 of 500\n",
      "working on feature 190 of 500\n",
      "working on feature 191 of 500\n",
      "working on feature 192 of 500\n",
      "working on feature 193 of 500\n",
      "working on feature 194 of 500\n",
      "working on feature 195 of 500\n",
      "working on feature 196 of 500\n",
      "working on feature 197 of 500\n",
      "working on feature 198 of 500\n",
      "working on feature 199 of 500\n",
      "working on feature 200 of 500\n",
      "working on feature 201 of 500\n",
      "working on feature 202 of 500\n",
      "working on feature 203 of 500\n",
      "working on feature 204 of 500\n",
      "working on feature 205 of 500\n",
      "working on feature 206 of 500\n",
      "working on feature 207 of 500\n",
      "working on feature 208 of 500\n",
      "working on feature 209 of 500\n",
      "working on feature 210 of 500\n",
      "working on feature 211 of 500\n",
      "working on feature 212 of 500\n",
      "working on feature 213 of 500\n",
      "working on feature 214 of 500\n",
      "working on feature 215 of 500\n",
      "working on feature 216 of 500\n",
      "working on feature 217 of 500\n",
      "working on feature 218 of 500\n",
      "working on feature 219 of 500\n",
      "working on feature 220 of 500\n",
      "working on feature 221 of 500\n",
      "working on feature 222 of 500\n",
      "working on feature 223 of 500\n",
      "working on feature 224 of 500\n",
      "working on feature 225 of 500\n",
      "working on feature 226 of 500\n",
      "working on feature 227 of 500\n",
      "working on feature 228 of 500\n",
      "working on feature 229 of 500\n",
      "working on feature 230 of 500\n",
      "working on feature 231 of 500\n",
      "working on feature 232 of 500\n",
      "working on feature 233 of 500\n",
      "working on feature 234 of 500\n",
      "working on feature 235 of 500\n",
      "working on feature 236 of 500\n",
      "working on feature 237 of 500\n",
      "working on feature 238 of 500\n",
      "working on feature 239 of 500\n",
      "working on feature 240 of 500\n",
      "working on feature 241 of 500\n",
      "working on feature 242 of 500\n",
      "working on feature 243 of 500\n"
     ]
    }
   ],
   "source": [
    "DTR_results = []\n",
    "counter = 1\n",
    "for feature in uci_no_target.columns:\n",
    "    print('working on feature {} of 500'.format(counter))\n",
    "    mean_scores = mean_r2_for_feature_dtr(uci_no_target, feature)\n",
    "    DTR_results.append(mean_scores)\n",
    "    counter +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DTR_columns = [x for x, score in enumerate(DTR_results) if score > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "any(i in KNN_columns for i in DTR_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Cook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target = cook_df['target']\n",
    "cook_no_target = cook_df.drop(['target'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_r2_for_feature_knn(data, feature):\n",
    "    new_data = data.drop(feature, axis=1)\n",
    "    \n",
    "    X_tr, \\\n",
    "    X_ts,  \\\n",
    "    y_tr, \\\n",
    "    y_ts = train_test_split(\n",
    "        new_data,data[feature],test_size=0.25\n",
    "    )\n",
    "    \n",
    "    regressor = KNeighborsRegressor()\n",
    "    regressor.fit(X_tr, y_tr)\n",
    "    \n",
    "    score = regressor.score(X_ts, y_ts)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mean_r2_for_feature_knn(data, feature):\n",
    "    scores = []\n",
    "    for _ in range(50):\n",
    "        scores.append(calculate_r2_for_feature_knn(data, feature))\n",
    "        \n",
    "    scores = np.array(scores)\n",
    "    return scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "KNN_results = []\n",
    "counter = 1\n",
    "for feature in uci_no_target.columns:\n",
    "    display('working on feature {} of 500'.format(counter))\n",
    "    mean_scores = mean_r2_for_feature_knn(uci_no_target, feature)\n",
    "    KNN_results.append(mean_scores)\n",
    "    counter +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "KNN_columns = [x for x, score in enumerate(KNN_results) if score > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "KNN_columns\n",
    "\n",
    "any(i in KNN_columns for i in DTR_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### UCI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_uci, X_test_uci, y_train_uci, y_test_uci = train_test_split(uci_df.drop(['labels'], axis=1), \n",
    "                                                    uci_df['labels'], test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf_pipe_uci = Pipeline([\n",
    "    ('clf',RandomForestClassifier())\n",
    "])\n",
    "\n",
    "rfparams_uci = {\n",
    "    'clf__n_estimators':[10,50,100,200],\n",
    "    'clf__max_features':['auto','log2']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rfgs_uci = GridSearchCV(rf_pipe_uci, rfparams_uci, cv=5, n_jobs=-1)\n",
    "\n",
    "rfgs_uci.fit(X_train_uci, y_train_uci)\n",
    "\n",
    "rfgs_uci.score(X_train_uci, y_train_uci)\n",
    "\n",
    "rfgs_uci.score(X_test_uci, y_test_uci)\n",
    "\n",
    "rfgs_uci.best_score_\n",
    "\n",
    "rfgs_uci.best_params_\n",
    "\n",
    "rf_results_uci = pd.DataFrame(rfgs_uci.cv_results_).sort_values('rank_test_score', ascending=True)\n",
    "rf_results_uci.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The best parameters were on the edge of params defined, so should run another grid search to see if i can do better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf_pipe_uci2 = Pipeline([\n",
    "    ('clf',RandomForestClassifier())\n",
    "])\n",
    "\n",
    "rfparams_uci2 = {\n",
    "    'clf__n_estimators': range(100,500,5),\n",
    "    'clf__max_features':['log2','sqrt']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rfgs_uci2 = GridSearchCV(rf_pipe_uci2, rfparams_uci2, cv=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Pipeline(steps=[('clf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False))]),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'clf__n_estimators': range(100, 500, 5), 'clf__max_features': ['log2', 'sqrt']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfgs_uci2.fit(X_train_uci, y_train_uci)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49090909090909091"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfgs_uci2.score(X_test_uci, y_test_uci)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.59393939393939399, {'clf__max_features': 'log2', 'clf__n_estimators': 490})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfgs_uci2.best_score_, rfgs_uci2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_clf__max_features</th>\n",
       "      <th>param_clf__n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.934501</td>\n",
       "      <td>0.045908</td>\n",
       "      <td>0.593939</td>\n",
       "      <td>1.0</td>\n",
       "      <td>log2</td>\n",
       "      <td>490</td>\n",
       "      <td>{'clf__max_features': 'log2', 'clf__n_estimato...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.552239</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.606061</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.569231</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002878</td>\n",
       "      <td>0.000720</td>\n",
       "      <td>0.031222</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>0.827117</td>\n",
       "      <td>0.027146</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>1.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>280</td>\n",
       "      <td>{'clf__max_features': 'sqrt', 'clf__n_estimato...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.552239</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.569231</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.630769</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.005898</td>\n",
       "      <td>0.000224</td>\n",
       "      <td>0.028265</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.783309</td>\n",
       "      <td>0.039594</td>\n",
       "      <td>0.587879</td>\n",
       "      <td>1.0</td>\n",
       "      <td>log2</td>\n",
       "      <td>410</td>\n",
       "      <td>{'clf__max_features': 'log2', 'clf__n_estimato...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.597015</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.651515</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.005228</td>\n",
       "      <td>0.000241</td>\n",
       "      <td>0.039934</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>0.734367</td>\n",
       "      <td>0.024344</td>\n",
       "      <td>0.587879</td>\n",
       "      <td>1.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>250</td>\n",
       "      <td>{'clf__max_features': 'sqrt', 'clf__n_estimato...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.582090</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.569231</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.630769</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002624</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>0.059369</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>1.453660</td>\n",
       "      <td>0.047232</td>\n",
       "      <td>0.584848</td>\n",
       "      <td>1.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>495</td>\n",
       "      <td>{'clf__max_features': 'sqrt', 'clf__n_estimato...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.522388</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.606061</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.007704</td>\n",
       "      <td>0.000301</td>\n",
       "      <td>0.031663</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "78        0.934501         0.045908         0.593939               1.0   \n",
       "116       0.827117         0.027146         0.590909               1.0   \n",
       "62        0.783309         0.039594         0.587879               1.0   \n",
       "110       0.734367         0.024344         0.587879               1.0   \n",
       "159       1.453660         0.047232         0.584848               1.0   \n",
       "\n",
       "    param_clf__max_features param_clf__n_estimators  \\\n",
       "78                     log2                     490   \n",
       "116                    sqrt                     280   \n",
       "62                     log2                     410   \n",
       "110                    sqrt                     250   \n",
       "159                    sqrt                     495   \n",
       "\n",
       "                                                params  rank_test_score  \\\n",
       "78   {'clf__max_features': 'log2', 'clf__n_estimato...                1   \n",
       "116  {'clf__max_features': 'sqrt', 'clf__n_estimato...                2   \n",
       "62   {'clf__max_features': 'log2', 'clf__n_estimato...                3   \n",
       "110  {'clf__max_features': 'sqrt', 'clf__n_estimato...                3   \n",
       "159  {'clf__max_features': 'sqrt', 'clf__n_estimato...                5   \n",
       "\n",
       "     split0_test_score  split0_train_score       ...         \\\n",
       "78            0.552239                 1.0       ...          \n",
       "116           0.552239                 1.0       ...          \n",
       "62            0.597015                 1.0       ...          \n",
       "110           0.582090                 1.0       ...          \n",
       "159           0.522388                 1.0       ...          \n",
       "\n",
       "     split2_test_score  split2_train_score  split3_test_score  \\\n",
       "78            0.606061                 1.0           0.600000   \n",
       "116           0.590909                 1.0           0.569231   \n",
       "62            0.651515                 1.0           0.538462   \n",
       "110           0.666667                 1.0           0.569231   \n",
       "159           0.606061                 1.0           0.600000   \n",
       "\n",
       "     split3_train_score  split4_test_score  split4_train_score  std_fit_time  \\\n",
       "78                  1.0           0.569231                 1.0      0.002878   \n",
       "116                 1.0           0.630769                 1.0      0.005898   \n",
       "62                  1.0           0.600000                 1.0      0.005228   \n",
       "110                 1.0           0.630769                 1.0      0.002624   \n",
       "159                 1.0           0.600000                 1.0      0.007704   \n",
       "\n",
       "     std_score_time  std_test_score  std_train_score  \n",
       "78         0.000720        0.031222              0.0  \n",
       "116        0.000224        0.028265              0.0  \n",
       "62         0.000241        0.039934              0.0  \n",
       "110        0.000255        0.059369              0.0  \n",
       "159        0.000301        0.031663              0.0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_results_uci2 = pd.DataFrame(rfgs_uci2.cv_results_).sort_values('rank_test_score', ascending=True)\n",
    "rf_results_uci2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "uci_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "importance_uci = rfgs_uci.best_estimator_.named_steps['clf'].feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.002705</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0\n",
       "0  0.001428\n",
       "1  0.002259\n",
       "2  0.002444\n",
       "3  0.001376\n",
       "4  0.002705"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_imp_uci = pd.DataFrame(importance_uci)\n",
    "feat_imp_uci.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mf_log_df_uci = rf_results_uci[rf_results_uci['param_clf__max_features'] == 'log2'][['param_clf__n_estimators','mean_test_score','mean_fit_time']]\n",
    "mf_auto_df_uci = rf_results_uci[rf_results_uci['param_clf__max_features'] == 'auto'][['param_clf__n_estimators','mean_test_score','mean_fit_time']]\n",
    "# making a mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\noYaiuIcQQg1FcQ8hhBqK4h5CCDX0D7LLKZJpi0BRAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f11d40e5eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(mf_auto_df_uci['param_clf__n_estimators'], \n",
    "         mf_auto_df_uci['mean_test_score'],\n",
    "         label = 'max feaures: auto')\n",
    "plt.plot(mf_log_df_uci['param_clf__n_estimators'], \n",
    "         mf_log_df_uci['mean_test_score'],\n",
    "         label = 'max feaures: log2')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "2    2\n",
       "3    3\n",
       "4    4\n",
       "dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_uci = pd.Series(uci_df.columns)\n",
    "features_uci.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>features</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001428</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002259</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002444</td>\n",
       "      <td>2</td>\n",
       "      <td>0.002444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001376</td>\n",
       "      <td>3</td>\n",
       "      <td>0.001376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.002705</td>\n",
       "      <td>4</td>\n",
       "      <td>0.002705</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0 features  importance\n",
       "0  0.001428        0    0.001428\n",
       "1  0.002259        1    0.002259\n",
       "2  0.002444        2    0.002444\n",
       "3  0.001376        3    0.001376\n",
       "4  0.002705        4    0.002705"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_imp_uci['features'] = features_uci\n",
    "feat_imp_uci['importance'] = importance_uci\n",
    "feat_imp_uci.drop(0, axis=1)\n",
    "feat_imp_uci.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feat_imp_uci.sort(importance_uci, axis=1, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
